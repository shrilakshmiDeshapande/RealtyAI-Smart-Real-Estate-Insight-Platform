{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cc7f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ENHANCED MODEL NOTEBOOK - INITIALIZED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ ENHANCED MODEL NOTEBOOK - INITIALIZED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca8763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DATA LOADED SUCCESSFULLY!\n",
      "Dataset shape: (3762566, 22)\n",
      "üéØ SELECTED REGION: alamocontra_costaca\n",
      "Region data shape: (261, 22)\n",
      "Date range: 1996-04-30 00:00:00 to 2017-12-31 00:00:00\n",
      "\n",
      "üéØ TOP 6 FEATURES SELECTED:\n",
      "  1. ZHVI_AllHomes\n",
      "  2. PctOfListingsWithPriceReductions_AllHomes\n",
      "  3. PriceToRentRatio_AllHomes\n",
      "  4. ZHVI_TopTier\n",
      "  5. Sale_Counts\n",
      "  6. MedianRentalPrice_AllHomes\n",
      "\n",
      "üîç DATA QUALITY CHECK:\n",
      "  ZHVI_AllHomes: 261/261 (100.0% complete)\n",
      "  PctOfListingsWithPriceReductions_AllHomes: 261/261 (100.0% complete)\n",
      "  PriceToRentRatio_AllHomes: 261/261 (100.0% complete)\n",
      "  ZHVI_TopTier: 261/261 (100.0% complete)\n",
      "  Sale_Counts: 261/261 (100.0% complete)\n",
      "  MedianRentalPrice_AllHomes: 261/261 (100.0% complete)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Load data and select enhanced features\n",
    "\n",
    "# Load the dataset\n",
    "zillow_ts = pd.read_csv('../data/zillow/zillow_cleaned_focused.csv')\n",
    "zillow_ts['Date'] = pd.to_datetime(zillow_ts['Date'])\n",
    "\n",
    "print(\"‚úÖ DATA LOADED SUCCESSFULLY!\")\n",
    "print(f\"Dataset shape: {zillow_ts.shape}\")\n",
    "\n",
    "# Select the same best region for fair comparison\n",
    "best_region = 'alamocontra_costaca'\n",
    "region_data = zillow_ts[zillow_ts['RegionName'] == best_region].sort_values('Date')\n",
    "\n",
    "print(f\"üéØ SELECTED REGION: {best_region}\")\n",
    "print(f\"Region data shape: {region_data.shape}\")\n",
    "print(f\"Date range: {region_data['Date'].min()} to {region_data['Date'].max()}\")\n",
    "\n",
    "# Define our top 6 features for enhanced model\n",
    "top_6_features = [\n",
    "    'ZHVI_AllHomes',                           # Primary target\n",
    "    'PctOfListingsWithPriceReductions_AllHomes', # Leading indicator\n",
    "    'PriceToRentRatio_AllHomes',               # Investment health\n",
    "    'ZHVI_TopTier',                            # Luxury segment leader\n",
    "    'Sale_Counts',                             # Market activity\n",
    "    'MedianRentalPrice_AllHomes'               # Fundamental value\n",
    "]\n",
    "\n",
    "print(\"\\nüéØ TOP 6 FEATURES SELECTED:\")\n",
    "for i, feature in enumerate(top_6_features, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "# Check data quality for these features\n",
    "print(\"\\nüîç DATA QUALITY CHECK:\")\n",
    "for feature in top_6_features:\n",
    "    non_null = region_data[feature].notna().sum()\n",
    "    total = len(region_data)\n",
    "    print(f\"  {feature}: {non_null}/{total} ({(non_null/total)*100:.1f}% complete)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1cb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ENHANCED DATA PREPARED:\n",
      "Shape: (261, 7)\n",
      "Date range: 1996-04-30 00:00:00 to 2017-12-31 00:00:00\n",
      "\n",
      "üìà FEATURE STATISTICS:\n",
      "       ZHVI_AllHomes  PctOfListingsWithPriceReductions_AllHomes  \\\n",
      "count   2.610000e+02                               2.610000e+02   \n",
      "mean    1.171327e+06                               1.267606e+01   \n",
      "std     3.463772e+05                               1.779770e-15   \n",
      "min     4.932000e+05                               1.267606e+01   \n",
      "25%     9.724000e+05                               1.267606e+01   \n",
      "50%     1.199900e+06                               1.267606e+01   \n",
      "75%     1.472500e+06                               1.267606e+01   \n",
      "max     1.804800e+06                               1.267606e+01   \n",
      "\n",
      "       PriceToRentRatio_AllHomes  ZHVI_TopTier  Sale_Counts  \\\n",
      "count                 261.000000  2.610000e+02   261.000000   \n",
      "mean                   14.263027  1.691074e+06    16.034483   \n",
      "std                     5.382073  4.011772e+05    10.925744   \n",
      "min                    10.500000  1.055300e+06     6.000000   \n",
      "25%                    10.500000  1.403200e+06     9.000000   \n",
      "50%                    10.500000  1.650600e+06     9.000000   \n",
      "75%                    21.190000  2.015200e+06    20.000000   \n",
      "max                    24.580000  2.629800e+06    57.000000   \n",
      "\n",
      "       MedianRentalPrice_AllHomes  \n",
      "count                       261.0  \n",
      "mean                       1400.0  \n",
      "std                           0.0  \n",
      "min                        1400.0  \n",
      "25%                        1400.0  \n",
      "50%                        1400.0  \n",
      "75%                        1400.0  \n",
      "max                        1400.0  \n",
      "\n",
      "üîç DATA SANITY CHECK:\n",
      "  ZHVI_AllHomes: 0 zeros, 0 negative values\n",
      "  PctOfListingsWithPriceReductions_AllHomes: 0 zeros, 0 negative values\n",
      "  PriceToRentRatio_AllHomes: 0 zeros, 0 negative values\n",
      "  ZHVI_TopTier: 0 zeros, 0 negative values\n",
      "  Sale_Counts: 0 zeros, 0 negative values\n",
      "  MedianRentalPrice_AllHomes: 0 zeros, 0 negative values\n",
      "\n",
      "üìä CORRELATION WITH TARGET (ZHVI_AllHomes):\n",
      "  ZHVI_AllHomes: 1.000\n",
      "  ZHVI_TopTier: 0.975\n",
      "  PriceToRentRatio_AllHomes: 0.488\n",
      "  Sale_Counts: 0.457\n",
      "  PctOfListingsWithPriceReductions_AllHomes: nan\n",
      "  MedianRentalPrice_AllHomes: nan\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Prepare enhanced data and analyze features\n",
    "\n",
    "# Extract our 6 features + Date\n",
    "enhanced_data = region_data[['Date'] + top_6_features].copy()\n",
    "\n",
    "print(\"üìä ENHANCED DATA PREPARED:\")\n",
    "print(f\"Shape: {enhanced_data.shape}\")\n",
    "print(f\"Date range: {enhanced_data['Date'].min()} to {enhanced_data['Date'].max()}\")\n",
    "\n",
    "# Check basic statistics of our features\n",
    "print(\"\\nüìà FEATURE STATISTICS:\")\n",
    "feature_stats = enhanced_data[top_6_features].describe()\n",
    "print(feature_stats)\n",
    "\n",
    "# Check for any zeros or outliers\n",
    "print(\"\\nüîç DATA SANITY CHECK:\")\n",
    "for feature in top_6_features:\n",
    "    zeros = (enhanced_data[feature] == 0).sum()\n",
    "    negative = (enhanced_data[feature] < 0).sum()\n",
    "    print(f\"  {feature}: {zeros} zeros, {negative} negative values\")\n",
    "\n",
    "# Quick correlation check with target\n",
    "print(\"\\nüìä CORRELATION WITH TARGET (ZHVI_AllHomes):\")\n",
    "correlations = enhanced_data[top_6_features].corr()['ZHVI_AllHomes'].sort_values(ascending=False)\n",
    "for feature, corr in correlations.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267e90d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ CHECKING AVAILABLE FEATURES IN YOUR DATASET:\n",
      "‚úÖ MedianListingPrice_AllHomes: std=600245.41, corr=0.537\n",
      "‚ùå MedianListingPrice_3Bedroom: NO VARIATION (std=0)\n",
      "‚úÖ ZHVI_MiddleTier: std=346377.23, corr=1.000\n",
      "‚úÖ ZHVI_BottomTier: std=283669.69, corr=0.993\n",
      "‚úÖ ZHVI_SingleFamilyResidence: std=347312.14, corr=1.000\n",
      "‚ùå ZHVI_CondoCoop: NO VARIATION (std=0)\n",
      "‚úÖ PctOfHomesIncreasingInValues_AllHomes: std=33.86, corr=-0.169\n",
      "\n",
      "üéØ SELECTED 2 ADDITIONAL FEATURES:\n",
      "  - ZHVI_MiddleTier\n",
      "  - ZHVI_SingleFamilyResidence\n",
      "\n",
      "‚úÖ FINAL FEATURE SET (6 features):\n",
      "  1. ZHVI_AllHomes\n",
      "  2. PriceToRentRatio_AllHomes\n",
      "  3. ZHVI_TopTier\n",
      "  4. Sale_Counts\n",
      "  5. ZHVI_MiddleTier\n",
      "  6. ZHVI_SingleFamilyResidence\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 FIX: Define improved_features first, then add 2 more\n",
    "\n",
    "# First, define our base improved features (from Step 3.5)\n",
    "improved_features = [\n",
    "    'ZHVI_AllHomes',                    # Primary target\n",
    "    'PriceToRentRatio_AllHomes',        # Investment health\n",
    "    'ZHVI_TopTier',                     # Luxury segment\n",
    "    'Sale_Counts'                       # Market activity\n",
    "]\n",
    "\n",
    "print(\"üîÑ CHECKING AVAILABLE FEATURES IN YOUR DATASET:\")\n",
    "\n",
    "# List of potential additional features to check\n",
    "potential_features = [\n",
    "    'MedianListingPrice_AllHomes',\n",
    "    'MedianListingPrice_3Bedroom', \n",
    "    'ZHVI_MiddleTier',\n",
    "    'ZHVI_BottomTier',\n",
    "    'ZHVI_SingleFamilyResidence',\n",
    "    'ZHVI_CondoCoop',\n",
    "    'PctOfHomesIncreasingInValues_AllHomes'\n",
    "]\n",
    "\n",
    "available_features = []\n",
    "for feature in potential_features:\n",
    "    if feature in region_data.columns:\n",
    "        non_null = region_data[feature].notna().sum()\n",
    "        std_val = region_data[feature].std()\n",
    "        if std_val > 0:  # Only include if it has variation\n",
    "            corr = region_data[feature].corr(region_data['ZHVI_AllHomes'])\n",
    "            available_features.append((feature, std_val, corr))\n",
    "            print(f\"‚úÖ {feature}: std={std_val:.2f}, corr={corr:.3f}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {feature}: NO VARIATION (std=0)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {feature}: NOT IN DATASET\")\n",
    "\n",
    "# Select top 2 available features based on correlation\n",
    "if len(available_features) >= 2:\n",
    "    available_features.sort(key=lambda x: abs(x[2]), reverse=True)  # Sort by correlation strength\n",
    "    selected_additional = [feature[0] for feature in available_features[:2]]\n",
    "    \n",
    "    print(f\"\\nüéØ SELECTED 2 ADDITIONAL FEATURES:\")\n",
    "    for feature in selected_additional:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    # Final feature set\n",
    "    final_features = improved_features + selected_additional\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not enough quality additional features available\")\n",
    "    final_features = improved_features  # Use original 4\n",
    "\n",
    "print(f\"\\n‚úÖ FINAL FEATURE SET ({len(final_features)} features):\")\n",
    "for i, feature in enumerate(final_features, 1):\n",
    "    print(f\"  {i}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed24b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TRAINING ENHANCED PROPHET MODEL WITH 6 FEATURES...\n",
      "üìä Training data shape: (261, 7)\n",
      "üéØ Target: ZHVI_AllHomes\n",
      "üìà Features: ['PriceToRentRatio_AllHomes', 'ZHVI_TopTier', 'Sale_Counts', 'ZHVI_MiddleTier', 'ZHVI_SingleFamilyResidence']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:32:47 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added regressor: PriceToRentRatio_AllHomes\n",
      "‚úÖ Added regressor: ZHVI_TopTier\n",
      "‚úÖ Added regressor: Sale_Counts\n",
      "‚úÖ Added regressor: ZHVI_MiddleTier\n",
      "‚úÖ Added regressor: ZHVI_SingleFamilyResidence\n",
      "\n",
      "‚è≥ Training in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:32:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Prophet model trained successfully!\n",
      "\n",
      "üìÖ Forecast period: 1996-04-30 00:00:00 to 2020-12-31 00:00:00\n",
      "üîÆ Future predictions: 36 months\n",
      "\n",
      "üîÆ KEY PREDICTIONS:\n",
      "Last known price (Dec 2017): $1,804,800\n",
      "1-year prediction: $1,804,814 (+0.0%)\n",
      "3-year prediction: $1,804,654 (-0.0%)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Train Enhanced Prophet Model with 6 Features\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "print(\"üöÄ TRAINING ENHANCED PROPHET MODEL WITH 6 FEATURES...\")\n",
    "\n",
    "# Prepare data for Prophet\n",
    "prophet_data = region_data[['Date'] + final_features].copy()\n",
    "prophet_data.columns = ['ds', 'y'] + final_features[1:]  # 'y' is ZHVI_AllHomes\n",
    "\n",
    "print(f\"üìä Training data shape: {prophet_data.shape}\")\n",
    "print(f\"üéØ Target: ZHVI_AllHomes\")\n",
    "print(f\"üìà Features: {final_features[1:]}\")\n",
    "\n",
    "# Initialize Prophet model\n",
    "model_enhanced = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "# Add all additional features as regressors\n",
    "for feature in final_features[1:]:  # Skip ZHVI_AllHomes (it's 'y')\n",
    "    model_enhanced.add_regressor(feature)\n",
    "    print(f\"‚úÖ Added regressor: {feature}\")\n",
    "\n",
    "# Fit the model\n",
    "print(\"\\n‚è≥ Training in progress...\")\n",
    "model_enhanced.fit(prophet_data)\n",
    "print(\"‚úÖ Enhanced Prophet model trained successfully!\")\n",
    "\n",
    "# Create future dataframe for predictions\n",
    "future = model_enhanced.make_future_dataframe(periods=36, freq='M')  # 3 years forecast\n",
    "\n",
    "# We need to provide future values for our regressors\n",
    "# For simplicity, we'll use the last known values (this is a limitation)\n",
    "for feature in final_features[1:]:\n",
    "    future[feature] = prophet_data[feature].iloc[-1]  # Use last available value\n",
    "\n",
    "# Make predictions\n",
    "forecast_enhanced = model_enhanced.predict(future)\n",
    "\n",
    "print(f\"\\nüìÖ Forecast period: {prophet_data['ds'].min()} to {future['ds'].max()}\")\n",
    "print(f\"üîÆ Future predictions: {len(future) - len(prophet_data)} months\")\n",
    "\n",
    "# Show key predictions\n",
    "print(\"\\nüîÆ KEY PREDICTIONS:\")\n",
    "last_known = prophet_data['y'].iloc[-1]\n",
    "pred_1yr = forecast_enhanced[forecast_enhanced['ds'] == future['ds'].iloc[-36]]['yhat'].iloc[0]\n",
    "pred_3yr = forecast_enhanced[forecast_enhanced['ds'] == future['ds'].iloc[-1]]['yhat'].iloc[0]\n",
    "\n",
    "growth_1yr = ((pred_1yr - last_known) / last_known) * 100\n",
    "growth_3yr = ((pred_3yr - last_known) / last_known) * 100\n",
    "\n",
    "print(f\"Last known price (Dec 2017): ${last_known:,.0f}\")\n",
    "print(f\"1-year prediction: ${pred_1yr:,.0f} ({growth_1yr:+.1f}%)\")\n",
    "print(f\"3-year prediction: ${pred_3yr:,.0f} ({growth_3yr:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8302bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:34:20 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FIXING MULTICOLLINEARITY ISSUES...\n",
      "‚úÖ FIXED FEATURE SET (removed perfect correlations):\n",
      "  1. ZHVI_AllHomes\n",
      "  2. PriceToRentRatio_AllHomes\n",
      "  3. Sale_Counts\n",
      "  4. ZHVI_TopTier\n",
      "\n",
      "‚è≥ Retraining with fixed features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:34:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ENHANCED MODEL PERFORMANCE:\n",
      "========================================\n",
      "R¬≤ Score: 0.9934 (99.3% variance explained)\n",
      "MAE: $22,288\n",
      "MAPE: nan%\n",
      "\n",
      "üéØ COMPARISON WITH BASELINE:\n",
      "Enhanced Model R¬≤: 0.9934\n",
      "Baseline Model R¬≤: 0.9699\n",
      "Improvement: +0.0235\n",
      "\n",
      "üîÆ IMPROVED PREDICTIONS:\n",
      "Last known price: $1,804,800\n",
      "1-year prediction: $1,818,317 (+0.7%)\n",
      "3-year prediction: $1,826,791 (+1.2%)\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Fix multicollinearity and evaluate model performance\n",
    "\n",
    "print(\"üîß FIXING MULTICOLLINEARITY ISSUES...\")\n",
    "\n",
    "# Remove perfectly correlated features (they don't add new information)\n",
    "# Keep only features that provide UNIQUE signals\n",
    "fixed_features = [\n",
    "    'ZHVI_AllHomes',                    # Target\n",
    "    'PriceToRentRatio_AllHomes',        # Unique signal (investment health)\n",
    "    'Sale_Counts',                      # Unique signal (market activity)\n",
    "    'ZHVI_TopTier'                      # Keep only one ZHVI segment (most correlated)\n",
    "]\n",
    "\n",
    "print(\"‚úÖ FIXED FEATURE SET (removed perfect correlations):\")\n",
    "for i, feature in enumerate(fixed_features, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "# Prepare fixed data\n",
    "prophet_data_fixed = region_data[['Date'] + fixed_features].copy()\n",
    "prophet_data_fixed.columns = ['ds', 'y'] + fixed_features[1:]\n",
    "\n",
    "# Train fixed model\n",
    "model_fixed = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "for feature in fixed_features[1:]:\n",
    "    model_fixed.add_regressor(feature)\n",
    "\n",
    "print(\"\\n‚è≥ Retraining with fixed features...\")\n",
    "model_fixed.fit(prophet_data_fixed)\n",
    "\n",
    "# Make predictions on TRAINING data to calculate R¬≤\n",
    "train_predictions = model_fixed.predict(prophet_data_fixed)\n",
    "\n",
    "# Calculate performance metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "actual_prices = prophet_data_fixed['y']\n",
    "predicted_prices = train_predictions['yhat']\n",
    "\n",
    "r2 = r2_score(actual_prices, predicted_prices)\n",
    "mae = mean_absolute_error(actual_prices, predicted_prices)\n",
    "mape = np.mean(np.abs((actual_prices - predicted_prices) / actual_prices)) * 100\n",
    "\n",
    "print(\"\\nüìä ENHANCED MODEL PERFORMANCE:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"R¬≤ Score: {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"MAE: ${mae:,.0f}\")\n",
    "print(f\"MAPE: {mape:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ COMPARISON WITH BASELINE:\")\n",
    "print(f\"Enhanced Model R¬≤: {r2:.4f}\")\n",
    "print(f\"Baseline Model R¬≤: 0.9699\")\n",
    "print(f\"Improvement: {r2 - 0.9699:+.4f}\")\n",
    "\n",
    "# Create future predictions with fixed model\n",
    "future_fixed = model_fixed.make_future_dataframe(periods=36, freq='M')\n",
    "for feature in fixed_features[1:]:\n",
    "    future_fixed[feature] = prophet_data_fixed[feature].iloc[-1]\n",
    "\n",
    "forecast_fixed = model_fixed.predict(future_fixed)\n",
    "\n",
    "# Show improved predictions\n",
    "print(\"\\nüîÆ IMPROVED PREDICTIONS:\")\n",
    "last_known = prophet_data_fixed['y'].iloc[-1]\n",
    "pred_1yr = forecast_fixed[forecast_fixed['ds'] == future_fixed['ds'].iloc[-36]]['yhat'].iloc[0]\n",
    "pred_3yr = forecast_fixed[forecast_fixed['ds'] == future_fixed['ds'].iloc[-1]]['yhat'].iloc[0]\n",
    "\n",
    "growth_1yr = ((pred_1yr - last_known) / last_known) * 100\n",
    "growth_3yr = ((pred_3yr - last_known) / last_known) * 100\n",
    "\n",
    "print(f\"Last known price: ${last_known:,.0f}\")\n",
    "print(f\"1-year prediction: ${pred_1yr:,.0f} ({growth_1yr:+.1f}%)\")\n",
    "print(f\"3-year prediction: ${pred_3yr:,.0f} ({growth_3yr:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2763ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING FOR OVERFITTING WITH PROPER VALIDATION...\n",
      "üìä PROPER TRAIN/TEST SPLIT:\n",
      "Training: 208 points (1996-04-30 00:00:00 to 2013-07-31 00:00:00)\n",
      "Testing:  53 points (2013-08-31 00:00:00 to 2017-12-31 00:00:00)\n",
      "\n",
      "‚è≥ Training on 80% of data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:36:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:36:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:36:15 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä REAL PERFORMANCE (on UNSEEN data):\n",
      "==================================================\n",
      "Test R¬≤ Score: 0.0555 (5.5% variance explained)\n",
      "Test MAE: $108,215\n",
      "Test MAPE: nan%\n",
      "\n",
      "üéØ HONEST COMPARISON:\n",
      "Training R¬≤ (potential overfitting): 0.9934\n",
      "Test R¬≤ (real performance): 0.0555\n",
      "Performance drop: 0.9379\n",
      "\n",
      "‚úÖ YOUR TARGET CHECK:\n",
      "Target: R¬≤ > 0.90\n",
      "Achieved: R¬≤ = 0.0555\n",
      "Status: ‚ùå BELOW TARGET\n",
      "\n",
      "üîç SIMPLE MODEL COMPARISON:\n",
      "(Training simple Prophet with only ZHVI_AllHomes on same split)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:36:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model (ZHVI only) test R¬≤: -3.7787\n",
      "Enhanced model test R¬≤: 0.0555\n",
      "Real improvement: +3.8342\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Proper validation to check for overfitting\n",
    "\n",
    "print(\"üîç CHECKING FOR OVERFITTING WITH PROPER VALIDATION...\")\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Proper time series split: Use first 80% for training, last 20% for testing\n",
    "split_point = int(len(prophet_data_fixed) * 0.8)\n",
    "train_data = prophet_data_fixed.iloc[:split_point]\n",
    "test_data = prophet_data_fixed.iloc[split_point:]\n",
    "\n",
    "print(f\"üìä PROPER TRAIN/TEST SPLIT:\")\n",
    "print(f\"Training: {len(train_data)} points ({train_data['ds'].min()} to {train_data['ds'].max()})\")\n",
    "print(f\"Testing:  {len(test_data)} points ({test_data['ds'].min()} to {test_data['ds'].max()})\")\n",
    "\n",
    "# Train on training period only\n",
    "model_proper = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "for feature in fixed_features[1:]:\n",
    "    model_proper.add_regressor(feature)\n",
    "\n",
    "print(\"\\n‚è≥ Training on 80% of data...\")\n",
    "model_proper.fit(train_data)\n",
    "\n",
    "# Test on unseen 20% of data\n",
    "test_forecast = model_proper.predict(test_data)\n",
    "\n",
    "# Calculate REAL performance (on unseen data)\n",
    "test_actual = test_data['y']\n",
    "test_predicted = test_forecast['yhat']\n",
    "\n",
    "test_r2 = r2_score(test_actual, test_predicted)\n",
    "test_mae = mean_absolute_error(test_actual, test_predicted)\n",
    "test_mape = np.mean(np.abs((test_actual - test_predicted) / test_actual)) * 100\n",
    "\n",
    "print(\"\\nüìä REAL PERFORMANCE (on UNSEEN data):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test R¬≤ Score: {test_r2:.4f} ({test_r2*100:.1f}% variance explained)\")\n",
    "print(f\"Test MAE: ${test_mae:,.0f}\")\n",
    "print(f\"Test MAPE: {test_mape:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ HONEST COMPARISON:\")\n",
    "print(f\"Training R¬≤ (potential overfitting): 0.9934\")\n",
    "print(f\"Test R¬≤ (real performance): {test_r2:.4f}\")\n",
    "print(f\"Performance drop: {0.9934 - test_r2:.4f}\")\n",
    "\n",
    "# Check if it meets your 90% criteria\n",
    "print(f\"\\n‚úÖ YOUR TARGET CHECK:\")\n",
    "print(f\"Target: R¬≤ > 0.90\")\n",
    "print(f\"Achieved: R¬≤ = {test_r2:.4f}\")\n",
    "print(f\"Status: {'‚úÖ EXCEEDS TARGET' if test_r2 > 0.90 else '‚ùå BELOW TARGET'}\")\n",
    "\n",
    "# Compare with simple model (ZHVI only) for fair comparison\n",
    "print(f\"\\nüîç SIMPLE MODEL COMPARISON:\")\n",
    "print(\"(Training simple Prophet with only ZHVI_AllHomes on same split)\")\n",
    "\n",
    "simple_train = train_data[['ds', 'y']].copy()\n",
    "simple_model = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.05)\n",
    "simple_model.fit(simple_train)\n",
    "\n",
    "simple_test_forecast = simple_model.predict(test_data[['ds', 'y']])\n",
    "simple_test_r2 = r2_score(test_actual, simple_test_forecast['yhat'])\n",
    "\n",
    "print(f\"Simple model (ZHVI only) test R¬≤: {simple_test_r2:.4f}\")\n",
    "print(f\"Enhanced model test R¬≤: {test_r2:.4f}\")\n",
    "print(f\"Real improvement: {test_r2 - simple_test_r2:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92d0e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:41:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ IMPLEMENTING PROPER TIME SERIES FORECASTING...\n",
      "üìä LAGGED DATA SHAPE: (249, 17)\n",
      "‚úÖ Using LAGGED features (no data leakage)\n",
      "\n",
      "üìà PROPER TRAIN/TEST SPLIT WITH LAGGED FEATURES:\n",
      "Training: 199 points\n",
      "Testing:  50 points\n",
      "\n",
      "‚è≥ Training with 12 LAGGED features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:41:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HONEST PERFORMANCE (PROPER TIME SERIES):\n",
      "==================================================\n",
      "Test R¬≤ Score: 0.5865 (58.6%)\n",
      "Test MAE: $64,158\n",
      "\n",
      "üéØ COMPARISON:\n",
      "Wrong approach (data leakage): R¬≤ = 0.0555\n",
      "Proper approach (lagged features): R¬≤ = 0.5865\n",
      "Improvement: +0.5310\n",
      "\n",
      "üí° REALITY CHECK:\n",
      "This is what ACTUAL time series forecasting looks like!\n",
      "No future knowledge - only historical patterns\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: PROPER TIME SERIES FORECASTING (No Data Leakage)\n",
    "\n",
    "print(\"üîÑ IMPLEMENTING PROPER TIME SERIES FORECASTING...\")\n",
    "\n",
    "# We can only use features that are AVAILABLE at prediction time\n",
    "# For housing markets, most features are available with 1-3 month lag\n",
    "\n",
    "# Strategy: Use LAGGED features (1-12 months behind)\n",
    "def create_lagged_features(data, features, lags=[1, 3, 6, 12]):\n",
    "    \"\"\"Create lagged versions of features for proper time series forecasting\"\"\"\n",
    "    data_lagged = data.copy()\n",
    "    for feature in features:\n",
    "        for lag in lags:\n",
    "            data_lagged[f'{feature}_lag_{lag}'] = data[feature].shift(lag)\n",
    "    return data_lagged\n",
    "\n",
    "# Create lagged features (proper approach)\n",
    "lagged_data = create_lagged_features(prophet_data_fixed, fixed_features[1:])\n",
    "\n",
    "# Remove rows with NaN (due to shifting)\n",
    "lagged_data_clean = lagged_data.dropna()\n",
    "\n",
    "print(f\"üìä LAGGED DATA SHAPE: {lagged_data_clean.shape}\")\n",
    "print(f\"‚úÖ Using LAGGED features (no data leakage)\")\n",
    "\n",
    "# Split chronologically\n",
    "split_idx = int(len(lagged_data_clean) * 0.8)\n",
    "train_lagged = lagged_data_clean.iloc[:split_idx]\n",
    "test_lagged = lagged_data_clean.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nüìà PROPER TRAIN/TEST SPLIT WITH LAGGED FEATURES:\")\n",
    "print(f\"Training: {len(train_lagged)} points\")\n",
    "print(f\"Testing:  {len(test_lagged)} points\")\n",
    "\n",
    "# Train model with lagged features only\n",
    "model_lagged = Prophet(yearly_seasonality=True)\n",
    "\n",
    "# Add all lagged features as regressors\n",
    "lagged_features = [col for col in lagged_data_clean.columns if 'lag_' in col]\n",
    "for feature in lagged_features:\n",
    "    model_lagged.add_regressor(feature)\n",
    "\n",
    "print(f\"\\n‚è≥ Training with {len(lagged_features)} LAGGED features...\")\n",
    "model_lagged.fit(train_lagged)\n",
    "\n",
    "# Test on unseen data\n",
    "test_forecast_lagged = model_lagged.predict(test_lagged)\n",
    "\n",
    "# Calculate REAL performance\n",
    "test_r2_lagged = r2_score(test_lagged['y'], test_forecast_lagged['yhat'])\n",
    "test_mae_lagged = mean_absolute_error(test_lagged['y'], test_forecast_lagged['yhat'])\n",
    "\n",
    "print(\"\\nüìä HONEST PERFORMANCE (PROPER TIME SERIES):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test R¬≤ Score: {test_r2_lagged:.4f} ({test_r2_lagged*100:.1f}%)\")\n",
    "print(f\"Test MAE: ${test_mae_lagged:,.0f}\")\n",
    "\n",
    "print(f\"\\nüéØ COMPARISON:\")\n",
    "print(f\"Wrong approach (data leakage): R¬≤ = 0.0555\")\n",
    "print(f\"Proper approach (lagged features): R¬≤ = {test_r2_lagged:.4f}\")\n",
    "print(f\"Improvement: {test_r2_lagged - 0.0555:+.4f}\")\n",
    "\n",
    "print(f\"\\nüí° REALITY CHECK:\")\n",
    "print(\"This is what ACTUAL time series forecasting looks like!\")\n",
    "print(\"No future knowledge - only historical patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb18ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:49:24 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ BUILDING HONEST, RELIABLE MODEL (FIXED VERSION)...\n",
      "üìã ACTUAL COLUMNS IN OUR DATA:\n",
      "['ds', 'y', 'PriceToRentRatio_AllHomes', 'Sale_Counts', 'ZHVI_TopTier']\n",
      "\n",
      "‚úÖ USING CORRECT FEATURES: ['y', 'PriceToRentRatio_AllHomes', 'ZHVI_TopTier']\n",
      "üìä CLEAN DATA SHAPE: (258, 6)\n",
      "\n",
      "üìä SIMPLE & RELIABLE APPROACH:\n",
      "Features used: ['PriceToRentRatio_AllHomes', 'ZHVI_TopTier']\n",
      "Training: 206 points\n",
      "Testing: 52 points\n",
      "\n",
      "‚è≥ Training simple model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:49:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HONEST FINAL RESULTS:\n",
      "========================================\n",
      "R¬≤ Score: 0.6740 (67.4%)\n",
      "MAE: $59,546\n",
      "\n",
      "üéØ COMPARISON WITH PREVIOUS BEST:\n",
      "Previous honest R¬≤: 58.6%\n",
      "Current honest R¬≤: 67.4%\n",
      "Change: +0.0875\n",
      "\n",
      "üíæ Model saved as 'reliable_prophet_model.joblib'\n",
      "\n",
      "üí° FINAL ASSESSMENT:\n",
      "‚úÖ SUCCESS! We improved performance with a simpler model!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print(\"üéØ BUILDING HONEST, RELIABLE MODEL (FIXED VERSION)...\")\n",
    "\n",
    "# Check what columns we actually have in prophet_data_fixed\n",
    "print(\"üìã ACTUAL COLUMNS IN OUR DATA:\")\n",
    "print(prophet_data_fixed.columns.tolist())\n",
    "\n",
    "# Use the CORRECT column names that actually exist\n",
    "best_features_correct = [\n",
    "    'y',                          # Target (this is ZHVI_AllHomes renamed)\n",
    "    'PriceToRentRatio_AllHomes', \n",
    "    'ZHVI_TopTier'\n",
    "]\n",
    "\n",
    "print(f\"\\n‚úÖ USING CORRECT FEATURES: {best_features_correct}\")\n",
    "\n",
    "# 2. Create simple lagged features\n",
    "simple_data = prophet_data_fixed[['ds'] + best_features_correct].copy()\n",
    "\n",
    "# Add only 3-month lags for the feature columns (skip 'y' which is target)\n",
    "for feature in best_features_correct[1:]:  # Skip target ('y')\n",
    "    simple_data[f'{feature}_lag_3'] = simple_data[feature].shift(3)\n",
    "\n",
    "simple_data_clean = simple_data.dropna()\n",
    "\n",
    "print(f\"üìä CLEAN DATA SHAPE: {simple_data_clean.shape}\")\n",
    "\n",
    "# 3. Use 80/20 split\n",
    "split_idx = int(len(simple_data_clean) * 0.8)\n",
    "train_simple = simple_data_clean.iloc[:split_idx]\n",
    "test_simple = simple_data_clean.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nüìä SIMPLE & RELIABLE APPROACH:\")\n",
    "print(f\"Features used: {best_features_correct[1:]}\")\n",
    "print(f\"Training: {len(train_simple)} points\")\n",
    "print(f\"Testing: {len(test_simple)} points\")\n",
    "\n",
    "# 4. Train simple model\n",
    "model_simple = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.05)\n",
    "\n",
    "# Add only the lagged features\n",
    "model_simple.add_regressor('PriceToRentRatio_AllHomes_lag_3')\n",
    "model_simple.add_regressor('ZHVI_TopTier_lag_3')\n",
    "\n",
    "print(\"\\n‚è≥ Training simple model...\")\n",
    "model_simple.fit(train_simple)\n",
    "\n",
    "# 5. Test honestly\n",
    "test_forecast_simple = model_simple.predict(test_simple)\n",
    "test_r2_simple = r2_score(test_simple['y'], test_forecast_simple['yhat'])\n",
    "test_mae_simple = mean_absolute_error(test_simple['y'], test_forecast_simple['yhat'])\n",
    "\n",
    "print(\"\\nüìä HONEST FINAL RESULTS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"R¬≤ Score: {test_r2_simple:.4f} ({test_r2_simple*100:.1f}%)\")\n",
    "print(f\"MAE: ${test_mae_simple:,.0f}\")\n",
    "\n",
    "print(f\"\\nüéØ COMPARISON WITH PREVIOUS BEST:\")\n",
    "print(f\"Previous honest R¬≤: 58.6%\")\n",
    "print(f\"Current honest R¬≤: {test_r2_simple*100:.1f}%\")\n",
    "print(f\"Change: {test_r2_simple - 0.5865:+.4f}\")\n",
    "\n",
    "# Save this reliable model\n",
    "joblib.dump(model_simple, 'reliable_prophet_model.joblib')\n",
    "print(f\"\\nüíæ Model saved as 'reliable_prophet_model.joblib'\")\n",
    "\n",
    "print(f\"\\nüí° FINAL ASSESSMENT:\")\n",
    "if test_r2_simple > 0.5865:\n",
    "    print(\"‚úÖ SUCCESS! We improved performance with a simpler model!\")\n",
    "elif test_r2_simple > 0.55:\n",
    "    print(\"‚úÖ GOOD! Similar performance but much simpler model!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OK! Simpler model, slightly lower performance but more reliable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
